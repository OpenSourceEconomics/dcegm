{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def policy_for_state_choice_vec(\n",
      "    state_choice_vec,\n",
      "    wealth,\n",
      "    map_state_choice_to_index,\n",
      "    discrete_states_names,\n",
      "    endog_grid_solved,\n",
      "    policy_solved,\n",
      "):\n",
      "    \"\"\"Get policy and value for a given state and choice vector.\n",
      "\n",
      "    Args:\n",
      "        state_choice_vec (Dict): Dictionary containing a single state and choice.\n",
      "        model (Model): Model object.\n",
      "        params (Dict): Dictionary containing the model parameters.\n",
      "\n",
      "    Returns:\n",
      "        Tuple[float, float]: Policy and value for the given state and choice vector.\n",
      "\n",
      "    \"\"\"\n",
      "    state_choice_tuple = tuple(\n",
      "        state_choice_vec[st] for st in discrete_states_names + [\"choice\"]\n",
      "    )\n",
      "\n",
      "    state_choice_index = map_state_choice_to_index[state_choice_tuple]\n",
      "\n",
      "    policy = interp_policy_on_wealth(\n",
      "        wealth=wealth,\n",
      "        endog_grid=jnp.take(endog_grid_solved, state_choice_index, axis=0),\n",
      "        policy=jnp.take(policy_solved, state_choice_index, axis=0),\n",
      "    )\n",
      "\n",
      "    return policy\n",
      "\n",
      "/Users/gregorschuler/GitProjects/dcegm/src/dcegm/interface.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "import jax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from dcegm.interface import policy_for_state_choice_vec\n",
    "from dcegm.pre_processing.setup_model import setup_model\n",
    "from dcegm.solve import solve_dcegm\n",
    "\n",
    "from toy_models.cons_ret_model_dcegm_paper.utility_functions_log_crra import (\n",
    "    utiility_log_crra,\n",
    "    utiility_log_crra_final_consume_all,\n",
    ")\n",
    "from toy_models.load_example_model import load_example_models\n",
    "\n",
    "import importlib\n",
    "import dcegm.interface\n",
    "importlib.reload(dcegm.interface)\n",
    "import inspect\n",
    "from dcegm.interface import policy_for_state_choice_vec\n",
    "\n",
    "print(inspect.getsource(policy_for_state_choice_vec))\n",
    "\n",
    "print(dcegm.interface.__file__)\n",
    "\n",
    "\n",
    "# set the jax_enable_x64 configuration option\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the test directory of the package\n",
    "TEST_DIR = Path(os.path.abspath(\"\")).parent\n",
    "REPLICATION_TEST_RESOURCES_DIR = TEST_DIR / \"resources\" / \"replication_tests\"\n",
    "\n",
    "\n",
    "def load_options_and_params(model_name):\n",
    "    \"\"\"Return parameters and options of an example model.\"\"\"\n",
    "    params = yaml.safe_load(\n",
    "        (REPLICATION_TEST_RESOURCES_DIR / f\"{model_name}\" / \"params.yaml\").read_text()\n",
    "    )\n",
    "    model_specs = yaml.safe_load(\n",
    "        (REPLICATION_TEST_RESOURCES_DIR / f\"{model_name}\" / \"options.yaml\").read_text()\n",
    "    )\n",
    "    return params, model_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"retirement_no_taste_shocks\"\n",
    "# model_name = \"retirement_taste_shocks\"\n",
    "# model_name = \"deaton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update function for state space not given. Assume states only change with an increase of the period and lagged choice.\n",
      "Sparsity condition not provided. Assume all states are valid.\n",
      "Starting state space creation\n",
      "State space created.\n",
      "\n",
      "Starting state-choice space creation and child state mapping.\n",
      "State, state-choice and child state mapping created.\n",
      "\n",
      "Start creating batches for the model.\n",
      "The batch size of the backwards induction is  3\n",
      "Model setup complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params, model_specs = load_options_and_params(model_name)\n",
    "options = {}\n",
    "\n",
    "options[\"model_params\"] = model_specs\n",
    "options[\"model_params\"][\"n_choices\"] = model_specs[\"n_discrete_choices\"]\n",
    "options[\"state_space\"] = {\n",
    "    \"n_periods\": 25,\n",
    "    \"choices\": [i for i in range(model_specs[\"n_discrete_choices\"])],\n",
    "    \"continuous_states\": {\n",
    "        \"wealth\": jnp.linspace(\n",
    "            0,\n",
    "            options[\"model_params\"][\"max_wealth\"],\n",
    "            options[\"model_params\"][\"n_grid_points\"],\n",
    "        )\n",
    "    },\n",
    "}\n",
    "\n",
    "model_funcs = load_example_models(\"dcegm_paper\")\n",
    "\n",
    "if model_name == \"deaton\":\n",
    "    model_funcs[\"state_space_functions\"] = None\n",
    "    model_funcs[\"utility_functions\"][\"utility\"] = utiility_log_crra\n",
    "    model_funcs[\"final_period_utility_functions\"][\n",
    "        \"utility\"\n",
    "    ] = utiility_log_crra_final_consume_all\n",
    "\n",
    "model = setup_model(\n",
    "    options=options,\n",
    "    state_space_functions=model_funcs[\"state_space_functions\"],\n",
    "    utility_functions=model_funcs[\"utility_functions\"],\n",
    "    utility_functions_final_period=model_funcs[\"final_period_utility_functions\"],\n",
    "    budget_constraint=model_funcs[\"budget_constraint\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update function for state space not given. Assume states only change with an increase of the period and lagged choice.\n",
      "Sparsity condition not provided. Assume all states are valid.\n",
      "Starting state space creation\n",
      "State space created.\n",
      "\n",
      "Starting state-choice space creation and child state mapping.\n",
      "State, state-choice and child state mapping created.\n",
      "\n",
      "Start creating batches for the model.\n",
      "The batch size of the backwards induction is  3\n",
      "Model setup complete.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "policy_for_state_choice_vec() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m consumption \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros_like(wealth_grid, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_id, wealth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wealth_grid):\n\u001b[0;32m---> 30\u001b[0m     policy_interp \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_for_state_choice_vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendog_grid_solved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendog_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_solved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_choice_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_choice_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwealth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwealth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     consumption[var_id] \u001b[38;5;241m=\u001b[39m policy_interp\n\u001b[1;32m     39\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(wealth_grid_to_test, consumption, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaste shock scale \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtaste_shock_scale\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: policy_for_state_choice_vec() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "for taste_shock_scale in [2.2204e-16, 0.01, 0.05, 0.10, 0.15]:\n",
    "\n",
    "    # set the taste shock scale\n",
    "    params[\"lambda\"] = taste_shock_scale\n",
    "\n",
    "    # solve the model\n",
    "    value, policy, endog_grid = solve_dcegm(\n",
    "        params=params,\n",
    "        options=options,\n",
    "        state_space_functions=model_funcs[\"state_space_functions\"],\n",
    "        utility_functions=model_funcs[\"utility_functions\"],\n",
    "        utility_functions_final_period=model_funcs[\"final_period_utility_functions\"],\n",
    "        budget_constraint=model_funcs[\"budget_constraint\"],\n",
    "    )\n",
    "\n",
    "    # look at the consumption policy for T-5 period, for a worker who decides to keep working (choice=0)\n",
    "    test_period = options[\"state_space\"][\"n_periods\"] - 5\n",
    "    state_choice_dict = {\n",
    "        \"period\": test_period,\n",
    "        \"lagged_choice\": 0,\n",
    "        \"dummy_exog\": 0,\n",
    "        \"choice\": 0,\n",
    "    }\n",
    "    # set wealth grid for plotting\n",
    "    wealth_grid = options[\"state_space\"][\"continuous_states\"][\"wealth\"]\n",
    "\n",
    "    # compute consumption policy for the wealth grid\n",
    "    consumption = jnp.zeros_like(wealth_grid, dtype=float)\n",
    "    for var_id, wealth in enumerate(wealth_grid):\n",
    "        policy_interp = policy_for_state_choice_vec(\n",
    "            endog_grid_solved=endog_grid,\n",
    "            policy_solved=policy,\n",
    "            model=model,\n",
    "            state_choice_vec=state_choice_dict,\n",
    "            wealth=wealth,\n",
    "        )\n",
    "        consumption[var_id] = policy_interp\n",
    "\n",
    "    plt.plot(\n",
    "        wealth_grid_to_test, consumption, label=f\"Taste shock scale {taste_shock_scale}\"\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Consumption\")\n",
    "plt.xlabel(\"Wealth\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcegm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
